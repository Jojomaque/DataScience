{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JojoSorting_and_cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jojomaque/DataScience/blob/main/JojoSorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* Sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* Sort by multiple columns e.g. \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make \n",
        "* Sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df` *original dataframe, df, will be as it was - unsorted* \n",
        "\n",
        "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n",
        "**Test output**:  \n",
        "The lowest score (displayed first) is 2.839, Togo  \n",
        "The highest score (displayed last) is 7.587, Switzerland  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "ace778c6-610e-456a-914b-fdfe2a60f9fc"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true')\n",
        "df\n",
        "happiness = df\n",
        "#Display first 5 rows\n",
        "happiness.head()\n",
        "sort_by_happiness_rank = happiness.sort_values(by = \"Happiness Score\",ascending = True)\n",
        "display(sort_by_happiness_rank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Happiness Rank</th>\n",
              "      <th>Happiness Score</th>\n",
              "      <th>Standard Error</th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Family</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "      <th>Freedom</th>\n",
              "      <th>Trust (Government Corruption)</th>\n",
              "      <th>Generosity</th>\n",
              "      <th>Dystopia Residual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>Togo</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>158</td>\n",
              "      <td>2.839</td>\n",
              "      <td>0.06727</td>\n",
              "      <td>0.20868</td>\n",
              "      <td>0.13995</td>\n",
              "      <td>0.28443</td>\n",
              "      <td>0.36453</td>\n",
              "      <td>0.10731</td>\n",
              "      <td>0.16681</td>\n",
              "      <td>1.56726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>Burundi</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>157</td>\n",
              "      <td>2.905</td>\n",
              "      <td>0.08658</td>\n",
              "      <td>0.01530</td>\n",
              "      <td>0.41587</td>\n",
              "      <td>0.22396</td>\n",
              "      <td>0.11850</td>\n",
              "      <td>0.10062</td>\n",
              "      <td>0.19727</td>\n",
              "      <td>1.83302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Syria</td>\n",
              "      <td>Middle East and Northern Africa</td>\n",
              "      <td>156</td>\n",
              "      <td>3.006</td>\n",
              "      <td>0.05015</td>\n",
              "      <td>0.66320</td>\n",
              "      <td>0.47489</td>\n",
              "      <td>0.72193</td>\n",
              "      <td>0.15684</td>\n",
              "      <td>0.18906</td>\n",
              "      <td>0.47179</td>\n",
              "      <td>0.32858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>Benin</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>155</td>\n",
              "      <td>3.340</td>\n",
              "      <td>0.03656</td>\n",
              "      <td>0.28665</td>\n",
              "      <td>0.35386</td>\n",
              "      <td>0.31910</td>\n",
              "      <td>0.48450</td>\n",
              "      <td>0.08010</td>\n",
              "      <td>0.18260</td>\n",
              "      <td>1.63328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>Rwanda</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>154</td>\n",
              "      <td>3.465</td>\n",
              "      <td>0.03464</td>\n",
              "      <td>0.22208</td>\n",
              "      <td>0.77370</td>\n",
              "      <td>0.42864</td>\n",
              "      <td>0.59201</td>\n",
              "      <td>0.55191</td>\n",
              "      <td>0.22628</td>\n",
              "      <td>0.67042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Canada</td>\n",
              "      <td>North America</td>\n",
              "      <td>5</td>\n",
              "      <td>7.427</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>1.32629</td>\n",
              "      <td>1.32261</td>\n",
              "      <td>0.90563</td>\n",
              "      <td>0.63297</td>\n",
              "      <td>0.32957</td>\n",
              "      <td>0.45811</td>\n",
              "      <td>2.45176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Norway</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>4</td>\n",
              "      <td>7.522</td>\n",
              "      <td>0.03880</td>\n",
              "      <td>1.45900</td>\n",
              "      <td>1.33095</td>\n",
              "      <td>0.88521</td>\n",
              "      <td>0.66973</td>\n",
              "      <td>0.36503</td>\n",
              "      <td>0.34699</td>\n",
              "      <td>2.46531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denmark</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>3</td>\n",
              "      <td>7.527</td>\n",
              "      <td>0.03328</td>\n",
              "      <td>1.32548</td>\n",
              "      <td>1.36058</td>\n",
              "      <td>0.87464</td>\n",
              "      <td>0.64938</td>\n",
              "      <td>0.48357</td>\n",
              "      <td>0.34139</td>\n",
              "      <td>2.49204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iceland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>2</td>\n",
              "      <td>7.561</td>\n",
              "      <td>0.04884</td>\n",
              "      <td>1.30232</td>\n",
              "      <td>1.40223</td>\n",
              "      <td>0.94784</td>\n",
              "      <td>0.62877</td>\n",
              "      <td>0.14145</td>\n",
              "      <td>0.43630</td>\n",
              "      <td>2.70201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switzerland</td>\n",
              "      <td>Western Europe</td>\n",
              "      <td>1</td>\n",
              "      <td>7.587</td>\n",
              "      <td>0.03411</td>\n",
              "      <td>1.39651</td>\n",
              "      <td>1.34951</td>\n",
              "      <td>0.94143</td>\n",
              "      <td>0.66557</td>\n",
              "      <td>0.41978</td>\n",
              "      <td>0.29678</td>\n",
              "      <td>2.51738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>158 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Country  ... Dystopia Residual\n",
              "157         Togo  ...           1.56726\n",
              "156      Burundi  ...           1.83302\n",
              "155        Syria  ...           0.32858\n",
              "154        Benin  ...           1.63328\n",
              "153       Rwanda  ...           0.67042\n",
              "..           ...  ...               ...\n",
              "4         Canada  ...           2.45176\n",
              "3         Norway  ...           2.46531\n",
              "2        Denmark  ...           2.49204\n",
              "1        Iceland  ...           2.70201\n",
              "0    Switzerland  ...           2.51738\n",
              "\n",
              "[158 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "1. Sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
        "2. Display the first 5 rows of sorted data \n",
        "\n",
        "**Test output**:  \n",
        "Records 122, 127, 147, 100, 96"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "061e9eb8-c0eb-42dc-e87d-d5d967188fb3"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true')\n",
        "df\n",
        "happiness_original = df\n",
        "#Display first 5 rows\n",
        "happiness_original.head()\n",
        "happiness_original.sort_values(['Economy (GDP per Capita)','Health (Life Expectancy)'])[['Economy (GDP per Capita)','Health (Life Expectancy)']].head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Economy (GDP per Capita)</th>\n",
              "      <th>Health (Life Expectancy)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.09806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>0.01530</td>\n",
              "      <td>0.22396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.01604</td>\n",
              "      <td>0.22562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0.06940</td>\n",
              "      <td>0.29707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.07120</td>\n",
              "      <td>0.34201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Economy (GDP per Capita)  Health (Life Expectancy)\n",
              "119                   0.00000                   0.09806\n",
              "156                   0.01530                   0.22396\n",
              "130                   0.01604                   0.22562\n",
              "143                   0.06940                   0.29707\n",
              "115                   0.07120                   0.34201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        " \n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n",
        "**Test output**:\n",
        "43, 7, 144, 0, 3 Country and Region columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "outputId": "3af7131d-07c5-450f-e635-39a955ecf8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "happiness_original.sort_values(['Freedom','Trust (Government Corruption)'],ascending = False)[['Country','Region']].tail()  #Please check my code as mu out put is different"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Angola</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Sudan</td>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Bosnia and Herzegovina</td>\n",
              "      <td>Central and Eastern Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Greece</td>\n",
              "      <td>Western Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Iraq</td>\n",
              "      <td>Middle East and Northern Africa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Country                           Region\n",
              "136                  Angola               Sub-Saharan Africa\n",
              "117                   Sudan               Sub-Saharan Africa\n",
              "95   Bosnia and Herzegovina       Central and Eastern Europe\n",
              "101                  Greece                   Western Europe\n",
              "111                    Iraq  Middle East and Northern Africa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values \n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"Make\"].isnull().values.any()`  \n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values \n",
        "---\n",
        "\n",
        "1. Read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
        "2. check if any NA values exist in the dataframe and print the result \n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
        "\n",
        "**Test output**:\n",
        "True\n",
        ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "outputId": "cddff4b3-2144-40f7-a511-2b6af10244bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv')\n",
        "housing_london_original = df\n",
        "housing_london_original.isnull().values.any()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQESL-vnHtM_",
        "outputId": "834709d2-f012-4b29-a3cb-8acbfad8aec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#.info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071)\n",
        "housing_london_original.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values \n",
        "---\n",
        "\n",
        "1. Remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
        "2. Remove all NA values across whole dataframe \n",
        "\n",
        "**Test output**:  \n",
        "1.  Row count reduced to 352 rows\n",
        "2.  Row count reduced to 267 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "outputId": "ccf2ba55-a029-410f-d3c4-f674f7ff9a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "#Remove rows with NA values for life_satisfaction\n",
        "df.dropna(subset = ['life_satisfaction'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>area</th>\n",
              "      <th>date</th>\n",
              "      <th>median_salary</th>\n",
              "      <th>life_satisfaction</th>\n",
              "      <th>mean_salary</th>\n",
              "      <th>recycling_pct</th>\n",
              "      <th>population_size</th>\n",
              "      <th>number_of_jobs</th>\n",
              "      <th>area_size</th>\n",
              "      <th>no_of_houses</th>\n",
              "      <th>borough_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>E09000002</td>\n",
              "      <td>barking and dagenham</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>28201.0</td>\n",
              "      <td>7.05</td>\n",
              "      <td>33568</td>\n",
              "      <td>30</td>\n",
              "      <td>187029.0</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>3780.0</td>\n",
              "      <td>71079.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>E09000003</td>\n",
              "      <td>barnet</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>30237.0</td>\n",
              "      <td>7.43</td>\n",
              "      <td>33062</td>\n",
              "      <td>34</td>\n",
              "      <td>357538.0</td>\n",
              "      <td>147000.0</td>\n",
              "      <td>8675.0</td>\n",
              "      <td>139346.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>E09000004</td>\n",
              "      <td>bexley</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>28638.0</td>\n",
              "      <td>7.42</td>\n",
              "      <td>31812</td>\n",
              "      <td>54</td>\n",
              "      <td>232774.0</td>\n",
              "      <td>78000.0</td>\n",
              "      <td>6429.0</td>\n",
              "      <td>95037.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>E09000005</td>\n",
              "      <td>brent</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>26772.0</td>\n",
              "      <td>7.11</td>\n",
              "      <td>29609</td>\n",
              "      <td>37</td>\n",
              "      <td>312245.0</td>\n",
              "      <td>115000.0</td>\n",
              "      <td>4323.0</td>\n",
              "      <td>112083.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>E09000006</td>\n",
              "      <td>bromley</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>28163.0</td>\n",
              "      <td>7.50</td>\n",
              "      <td>32863</td>\n",
              "      <td>50</td>\n",
              "      <td>310554.0</td>\n",
              "      <td>119000.0</td>\n",
              "      <td>15013.0</td>\n",
              "      <td>135036.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>E12000009</td>\n",
              "      <td>south west</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>27956.0</td>\n",
              "      <td>7.77</td>\n",
              "      <td>32848</td>\n",
              "      <td>50</td>\n",
              "      <td>5599735.0</td>\n",
              "      <td>3011000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>E92000001</td>\n",
              "      <td>england</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>29856.0</td>\n",
              "      <td>7.71</td>\n",
              "      <td>37313</td>\n",
              "      <td>44</td>\n",
              "      <td>55977178.0</td>\n",
              "      <td>30493000.0</td>\n",
              "      <td>13303728.0</td>\n",
              "      <td>24172166.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>N92000002</td>\n",
              "      <td>northern ireland</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>27101.0</td>\n",
              "      <td>7.89</td>\n",
              "      <td>31158</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1881641.0</td>\n",
              "      <td>900000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1018</th>\n",
              "      <td>S92000003</td>\n",
              "      <td>scotland</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>29289.0</td>\n",
              "      <td>7.69</td>\n",
              "      <td>34604</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5438100.0</td>\n",
              "      <td>2861000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1019</th>\n",
              "      <td>W92000004</td>\n",
              "      <td>wales</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>26353.0</td>\n",
              "      <td>7.68</td>\n",
              "      <td>30347</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3138631.0</td>\n",
              "      <td>1496000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>352 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           code                  area  ... no_of_houses  borough_flag\n",
              "613   E09000002  barking and dagenham  ...      71079.0             1\n",
              "614   E09000003                barnet  ...     139346.0             1\n",
              "615   E09000004                bexley  ...      95037.0             1\n",
              "616   E09000005                 brent  ...     112083.0             1\n",
              "617   E09000006               bromley  ...     135036.0             1\n",
              "...         ...                   ...  ...          ...           ...\n",
              "1010  E12000009            south west  ...          NaN             0\n",
              "1013  E92000001               england  ...   24172166.0             0\n",
              "1017  N92000002      northern ireland  ...          NaN             0\n",
              "1018  S92000003              scotland  ...          NaN             0\n",
              "1019  W92000004                 wales  ...          NaN             0\n",
              "\n",
              "[352 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n",
        "\n",
        "**Test output**:  \n",
        " Dataframe now contains 50 rows all with date 1999-12-*01* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "# Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
        "\n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "To normalise we need to:\n",
        "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
        "\n",
        "For example:  \n",
        "```\n",
        "def normalise_bmi(df):\n",
        "  if df['bmi'] >= 25:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
        "```\n",
        "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8KPmy2_NVh1"
      },
      "source": [
        "### Exercise 7 - normalise data set\n",
        "---\n",
        "\n",
        "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
        "\n",
        "Apply the normalise_income(df) function to the `median_salary` column.\n",
        "\n",
        "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktylpCl7QjGJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrIEyMjSYTI"
      },
      "source": [
        "### Exercise 8 - normalise the number of jobs column\n",
        "---\n",
        "\n",
        "Using what you have learnt from Exercise 7:  \n",
        "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
        "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
        "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYXovr-T7TB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akqnUbYVblH"
      },
      "source": [
        "## Exercise 9 - normalise into a new column\n",
        "---\n",
        "\n",
        "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQsE4znV6nD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FaL31EXHZX"
      },
      "source": [
        "### Exercise 10 - normalise boroughs\n",
        "---\n",
        "\n",
        "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
        "\n",
        "**Test output**:  \n",
        "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIZ9M0UXkkv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}